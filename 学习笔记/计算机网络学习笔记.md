---
开始日期: 2022-09-19
上次编辑日期: 2022-09-24
标签: 学习笔记 计算机 前端
---

# 计算机网络 学习笔记

#### 计算机网络和因特网
- 第一章概述计算机网络和因特网的基础内容，以下从端系统或者主机概述因特网的基本构成。
	- **端系统**通过**通信链路**和**分组交换机**连接。通信链路由**物理媒体**组成，这些物理媒体决定了它的传输速率。端系统之间发送数据时，发送端系统将数据分段并添加首部字节，这被称为**分组**。分组被发送到目的端系统后重新装配为初始数据。分组交换机从它的入通信链路接收分组，并从它的出通信链路转发该分组。典型的分组交换机有**路由器**和**链路层交换机**，它们向最终目的地转发分组。前者通常用于**网络核心**中，后者通常用于**接入网**中。从发送端系统到接收端系统，一个分组经历的一系列通信链路和分组交换器被称为通过该网络的**路径**。
	- 端系统通过**因特网服务提供商**（**ISP**）接入因特网。每个因特网服务自身就是一个由多台分组交换机和多段通信链路组成的网络。为了实现端系统的互联，因特网服务之间也必须互联。较低层的因特网服务通过国家的、国际的较高层因特网服务连接。较高层因特网服务由通过高速光纤链路互联的高速路由器组成。因特网服务是独立管理的，运行 IP 协议，遵循一定的命名和地址规则。
	- 端系统、分组交换机和其他因特网部件都要运行一系列**协议**，这些协议控制因特网中信息的接收与发送。传输控制协议（**TCP**）和网际协议（**IP**）是因特网中最重要的两个协议。后者定义了在路由器和端系统之间发送和接收的分组格式。因特网的主要协议统称为 TCP/IP 。因特网标准由因特网工程任务组（IETF）研发，它的标准文档被称为请求评论（RFC）。
- **分布式应用程序**，涉及多个相互交换数据的端系统的应用程序。
	- 因特网应用程序运行在端系统上，而非运行在网络核心中的分组交换机中。*分组交换机只用于数据交换。* 因特网也因此又被描述为应用程序的平台。
- **套接字接口**，由端系统提供，它规定了运行在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式。
	- 它是发送数据必须遵循的规则的集合，据此因特网能够将数据交付给目的地。
- **协议**定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和/或接收一条报文或其他事件所采取的动作。
	- 发送特定的报文，根据接收到的应答报文或其他事件采取动作。
	- 在因特网中，涉及两个或多个远程通信实体的所有活动都受协议的制约。
	- *掌握计算机网络领域知识的过程，就是理解网络协议的构成、原理和工作方式的过程。*
- **端系统**，也称为**主机**，用于容纳（运行）应用程序。端系统被划分为客户端与服务器。服务器可能构成数据中心；数据中心由服务器组成。
- **边缘路由器**是将端系统连接到任何其他远程端系统的路径上的第一台路由器。**接入网**是指将端系统物理连接到边缘路由器的网络。*关于物理连接。*
	- 传统的家庭接入的方式有数字用户线、电缆因特网接入、光纤到户、卫星接入和拨号接入。
	- 在企业和新型的家庭环境中，使用局域网（LAN）将端系统连接到边缘路由器。以太网是最流行的局域网接入技术，基于 IEEE 802.11 技术的无线局域网接入被称为 Wifi 。
	- 移动设备也使用广域无线接入，这使用与蜂窝无线电话相同的无线基础设施，通过蜂窝网提供商运营的基站来发送和接收分组。
	- *接入网也就是接入因特网服务（ISP）。*
- 因特网须经由**物理媒体**传播电磁波或光脉冲以传输数据。 *即上述物理连接。* 这些物理媒体组成通信链路。
	- 物理媒体分为导引型和非导引型，对于前者，电波沿固体媒体传播，对于后者，电波在空气或外层空间传播。
	- 导引型媒体有双绞铜线、同轴电缆和光纤，非导引型媒体有陆地无线电信道和卫星无线电信道，陆地无线电信道有短程、局域和广域。
- 以上至端系统是网络边缘或接入网的内容，以下讨论**网络核心**，即由互联因特网端系统的分组交换机和链路构成的网状网络。 ^network-core
- 在网络应用中，端系统彼此交换**报文**，其中包含协议设计者需要的任何东西，包括可执行功能和数据。为了从源端系统向目的端系统发送报文，源将长报文划分为较小的数据块，这被称为**分组**。在源和目的地之间，每个分组都要通过通信链路和**分组交换机**传送。（交换机分为**路由器**和**链路层交换机**。）分组以等于该链路最大传输速率的速度传输通过通信链路。
- 多数分组交换机在链路的输入端使用**存储转发运输机制**。它是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。
	- 为此，在交换机输出该分组前，须缓存之，直到接收到整个分组。这意味着在分组交换机处产生**时延**，如果一条路径上有多个分组交换机，则产生多个时延。这被称为**存储转发时延**。
- 分组交换机有多条链路连接，对于每条链路，该分组交换机具有一个**输出缓存**，也称为**输出队列**，用于存储交换机准备发往那条链路的分组。当到达的分组需要发送到某条输出链路，而该链路正输出其他分组时，该到达分组必须在输出缓存中等待。这产生**排队时延**。
	- 由于缓存空间是有限的，当一个分组到达时该缓存已被其他等待传输的分组占满，则到达的分组或排队的分组之一将被丢弃，这被称为**分组丢失**（**丢包**）。
- 在因特网中，每个端系统具有 IP 地址，IP 地址具有等级结构。路由器根据**转发表**将分组首部的包含的目的地的 IP 地址（即目的地址）或其一部分映射为输出链路，据此决定将该分组发往哪条链路。*等级结构的IP地址，例如 66.249.66.194 ，可能是第一个路由器识别 66 ，然后发往最近的路由，第二个识别 66.249 ，这样一层一层地导向最终目的地。*
- 通过网络链路和交换机移动数据有两种基本的方法，分别是**电路交换**和**分组交换**。在端系统通信会话期间，电路交换网络创建了专用的**端到端连接**，预留了端系统间沿路径通信所需要的资源，这些资源包括缓存、链路传输速率（预留链路传输容量的固定部分则发送方能以确保的恒定速率向接收方发送数据）。*可以将电路交换与分组交换分别比作预约与排队两种资源分配方式。* 分组交换则不能保证以实时方式交付分组，因为可能出现拥塞与排队时延，甚至丢包。
	- 电路交换通过**频分复用**或**时分复用**实现。在频分复用中，链路的频谱由跨越链路创建的所有连接共享，在连接期间，为连接指定专用频段。这一频段的宽度被称为**带宽**。对于时分复用，时间（时域）被划分为固定期间的帧，每个帧又被划分为固定数量的时隙，为连接指定专用时隙。
	- 由于多个用户同时活跃而导致分组交换链路拥塞的概率极低，而电路交换由于在**静默期**导致专用电路空闲以及少数的活跃用户无法使用空闲的容量而不经济，总之，电路交换预先分配传输链路的使用而不考虑实际的需求，分组交换则实时地按照需求分配链路的使用，因此分组交换的性能优于电路交换。分组交换是发展趋势，传统的电路交换电话网也在缓慢地向分组交换过渡。
- 因特网服务（ISP）之间形成的网络也被称为「网络的网络」，书中提到，理解这个短语是理解因特网的关键。*尤其是它的结构。*
	- 接入因特网服务的**客户**需要根据其交换的流量向**提供商**支付费用。客户是较小的因特网服务提供商，它向更底层的提供商收费，直到网络边缘，向最终用户（家庭或企业）收费。
	- *这里，客户与提供商一起提出时，它们是对等的概念；当提供商单独提出时，它就是指一切因特网服务的提供商。*
	- 在多层等级网络结构的基础上，处于相同位置的路由器组成的群组（集合）被称为**存在点**，在此群组中客户与提供商连接。存在点存在于除底层外的任何层次中，且除底层外任何提供商都可以选择**多宿**，即与两个或更多提供商连接。这样可以在它的提供商之一发生故障时保证数据的传输。
	- 上面提到，客户须向提供商支付费用。为了减少这些费用，位于相同等级结构层次的邻近提供商直接地将它们的网络连接在一起，而不必经由上游提供商，这被称为**对等**。底层提供商之间也存在对等，顶层提供商之间也对等。对等的提供商之间通常不结算，即任一提供商不向其对等付费。以此为前提，第三方公司创立**因特网交换点**（IXP），便利符合条件的提供商对等，提供商也可经由交换点对等。
	- 上述的网络结构描述了如今的互联网，不过有如谷歌的**内容提供商网络**通过对等或经由交换点对等绕过较高层的提供商，以此减少向顶层服务商的付费，并获取更多的话语权。当然，一般的内容提供商和用户一样是较低层提供商的客户，*只有谷歌这样的巨佬才这样玩*。
- *[[2022-09-19]] ，下午，五个小时，至 25 页，1.3 完。*
---
- 分组自源出发，经历一系列路由器或主机（它们被称为节点），最终到达目的端。在每个节点，产生时延，包括节点处理时延、排队时延、传输时延和传播时延等。它们的和是**节点总时延**。
	- **处理时延**主要包括检查分组首部并决定将该分组导向何处所需要的时间，它也包括检查比特级别的差错等其他处理所需要的时间。处理时延由路由器的性能决定。
	- **传输时延**是将分组的所有比特推向链路所需要的时间。以 L 比特表示分组的长度，R bps 表示自此路由器至下一路由器的链路传输速率（路由器推出比特的速率），则传输时延是 L/R 。实际的传输时延在毫秒到微秒量级。*传输时延即等待该分组中的所有比特到达（被存储在）节点所需要的时间，这样路由器才能将分组中的所有比特推向链路。到达与被推送向链路可以称为经过该节点，则传输时延是该分组经过某一节点的时间。但为什么它被至下一路由器的链路传输速率决定 #？* *分组中的所有比特进出路由器用的时间。*
	- 某一比特被推向链路后，自该链路的起点至下一路由器传播所需要的时间是**传播时延**。它等于两台路由器之间的距离除以传播速率。在广域网中，传播时延在毫秒量级。
- 由于对于特定分组，其**排队时延**是不确定的，因此表征排队时延时常使用统计量。排队时延的值取决于流量到达该队列的速率、链路的传输速率和到达流量的性质，后者即流量是周期性到达还是以突发形式到达。
	- 令 a 表示分组到达队列的平均速率（单位为分组每秒），则比特到达队列的平均速率为 La bps 。如上，R 表示从队列中推出比特的速率，单位为 bps （b/s）。那么，比率 La/R 被称为**流量强度**。（*即比特到达队列的速率与队列推出比特的速率的比，或者说队列进出量之比。*）可见，当流量强度大于 1 时，队列将趋于无限增加，队列时延将趋于无限大。因此，设计系统时，流量强度不能大于 1 。 ^traffic-intensity
	- 当流量强度不大于 1 时，如果分组以突发形式到达，可能有较大的平均排队时延；如果分组周期性到达，可能不会有排队时延。*突发与周期，影响同时到达的分组数。*
	- 表征平均排队时延与流量强度之间关系的函数呈 J 形，这表明随着流量强度接近于 1 ，平均排队时延迅速增加。此时，该强度的少量增加，将导致时延大比例增加。
	- 现实中，由于队列容量是有限的，当流量强度较大时，队列并不会无限增加，队列填满时新到达的分组将被丢弃，这被称为**丢包**。分组丢失的比例随流量强度的增大而增加。（队列填满后到达分组被称为溢出。）
- 节点时延的和为**端到端时延**。端系统间还存在根据协议的共享媒体时延、媒体分组化时延等其他时延。
- 除时延与丢包外，计算机网络的另一性能测度是**端到端吞吐量**。**瞬时吞吐量**是指在任一瞬间接收端接收比特的速率，其单位为 bps 。某一文件传输的**平均吞吐量**为该文件的比特量（用 F 表示）比传送时间（T），即 F/T bps 。文件传输要求有较高的吞吐量。*bps 即 b/s ，其进制有 kb/s ，mb/s 等，下载文件所显示的速度便是瞬时吞吐量。*
	- 仅考虑传播时延，则吞吐量取决于路径中传输速率最小的链路的传输速率，也就是，取决于**瓶颈链路**的传输速率。据此，在当前的因特网中，限制吞吐量的通常是接入网。
	- 并且，由于链路传播速率由同时传输的所有流量共享，因此，吞吐量不仅取决于沿着路径的传输速率，也取决于干扰流量。
- *[[2022-09-20]]，上午，两个小时，至32页，1.4 完。*
---
- 书中以航班为例，指出航班的服务分层次，且每一层次与其下面的层次结合在一起，实现某些功能、服务。每个层次通过两种方式提供服务：一是在这层中执行某些动作；二是直接使用下层的服务。*以航班为例，则数据类比为乘客，因特网类比为航班，这里所说的服务是因特网（航班）提供的服务，执行某些动作是数据执行动作，或者说承载可执行动作的数据。*
	- 这些层次模块化地组成复杂的系统，当某层服务发生改变时，只要该层对其上面的层提供相同的服务，并且使用来自下面的层的相同的服务，该系统的其余部分保持不变。*可见，这里所说的服务是上下层之间相互提供的服务。*
- 在网络协议结构中，网络设计者以**分层**的方式组织协议以及实现这些协议的网络硬件和软件。每个协议属于这些层次之一，它向上一层提供的**服务**便是这一层的**服务模型**。每层通过在该层中执行某些动作或直接使用下层的服务来提供服务。*后者可能是它（组合）利用（多个）下层的服务来提供服务。*
	- 协议层通过软件、硬件或两者的结合实现。诸如 HTTP 和 SMTP 这样的应用层协议总是在端系统中软件实现；运输层协议也如此；物理层和数据链路层负责处理跨越特定链路的通信，它们通常在与给定链路相关联的网络接口卡中实现；网络层经常是硬件与软件实现的混合。协议层总是分布在构成该网络的端系统、分组交换机和其他组件中。
	- 协议分层具有概念化与结构化的特点，可以模块化地组成复杂的系统，但它可能的缺点在于冗余（某一层冗余较低层的功能）与依赖（某层的功能需要仅在其他某层才出现的信息）。
- 综上，各层的所有协议组成**协议栈**，因特网的协议栈由五个层次组成，**自顶向下**分别是：应用层、运输层、网络层、链路层和物理层。这便是所谓**因特网的体系结构**。
	- **应用层**是网络应用程序以及它们的应用层协议存留的地方。例如负责 Web 文档的请求和传送的 HTTP 协议；负责电子邮件报文传送的 SMTP 协议；负责两个端系统之间文件传送的 FTP 协议；域名系统 DNS 协议。
	- 应用层协议分布在多个端系统上，跨端的应用程序之间使用协议交换信息分组。位于应用层的信息分组被称为**报文**。
	- **运输层**在应用程序端点之间传送应用层报文。有两种应用层协议，即 **TCP** 与 UDP 。（*应用程序端点大概是应用程序端口*）TCP 向它的应用程序提供了面向连接的服务，将长报文划分为短报文，确保报文传递并控制其速率（包括流量控制，即使发送方与接收方的速率匹配，和拥塞控制，即当网络拥塞时，源抑制其传输速率）。UDP 向它的应用程序提供无连接服务（*这似乎是一种更简单的协议，书中提到它没有可靠性*）。运输层的分组被称为**报文段**。*忽略 UDP ，则运输层就是大名鼎鼎的 TCP 。*
	- **网络层**负责根据运输层协议提交的运输报文段和目的地址将称为**数据报**的网络层分组从源移动到目的端系统。网络层包括著名的**网际协议**（**IP**） ，该协议定义了数据包中的各个字段以及端系统和路由器如何作用这些于这些字段。任何具有网络层协议的因特网组件必须运行 IP 。网络层也包括决定路由的**路由选择协议**，它根据该路由将数据报从源传输到目的地；这表明，网络层通过源和目的地之间的一系列路由器路由数据报。网络层又被称为 IP 层。
	- 为了将分组从节点上移动到下个节点，网络层必须依靠**链路层**的服务。在每个节点，网络层将数据报下传给链路层，链路层沿路径将其传递给下个节点；在下个节点，链路层将数据报上传给网络层。链路层提供的服务取决于其采用的特定的链路层协议，例如以太网、 WiFi 和电缆接入网的 DOCSIC 协议。路径上存在多段链路时，网络层可能将被不同的链路层协议服务。链路层分组被称为**帧**。
	- 链路层将整个帧从网络元素移动到邻近的网络元素，**物理层**的任务则是将该帧中的一个个比特从一个节点移动到下个节点。某一链路采用的物理层协议与该链路的物理媒体相关。
- 除上述的因特网协议栈以外，上世纪七十年代国际标准化组织提出七层的开放系统互联（**OSI**）模型，在应用层与运输层之间有额外的表示层与会话层。表示层使通信的应用程序解释交换数据的含义（*语义*），这包括自解释的数据压缩和数据加密，以及数据描述。会话层提供了数据交换的定界和同步问题。
	- OSI 模型是互联网发展的雏形，它仅存留在教科书中。在普遍使用因特网协议栈的前提下，开发者可在应用程序中选择性地构建这些服务。
- 处于网络核心的由链路层交换机与路由器，前者仅能实现链路层与物理层功能，这意味着它并不能识别 IP 地址，尽管可以识别链路层地址如以太网地址，后者仅能实现网络层、链路层与物理层功能；而处于网络边缘的端系统支持所有协议栈。这表明，因特网体系结构将它的复杂性放在网络边缘。
- 源端的**应用层报文**被发送到运输层时，运输层为其附上运输层首部信息，该信息将被接收端的运输层使用。应用层报文与运输层首部信息构成**运输层报文段**。这一过程被称为**封装**。
	- 类似地，运输层向网络层传递该报文段后，网络层将其封装为**网络层数据报**；该数据报传递给链路层后被链路层封装为**链路层帧**。*物理层无封装。*
	- 由此，在每一层，一个分组具有两种类型的字段，即**首部字段**和**有效荷载字段**。有效荷载通常来自上层的分组。
	- 报文较长时，封装中可能被划分为多个报文段，这些报文段可能被划分为多个数据报。在接收端则从连续的数据报中重构报文段，从报文段中重构报文。
- 1.5 节结束，下面是 1.6 节〈面对攻击的网络〉的内容。网络攻击有以下几种情况。
	- 甲、对主机的攻击，这表现为攻击者经因特网将有害程序植入主机中。被控制的主机形成网络被称为**僵尸网络**。大多数恶意软件是自我复制的，它们被称为**病毒**。不须显示交互即可进入设备的恶意软件被称为**蠕虫**。
	- 乙、对服务器和网络基础设施的攻击，这主要表现为**拒绝服务攻击**（**DoS**），即使网络、主机或其他基础设施部分不能被合法用户使用，包括弱点攻击（发送应用程序或长报文使主机或服务器停止运行甚至崩溃）、带宽洪泛（向目标主机发送大量分组使其接入链路拥塞）、连接洪泛（在目标主机中创建大量 TCP 连接，使其停止接受合法的连接）。
	- 在带宽洪泛的攻击中，为了使服务器接入链路拥塞，攻击源须至少产生与主机接入速率相近的流量才能造成危害，单一攻击源可能无法产生足够的流量、也易被上游路由器察觉而拦截，在此情况下，**分布式 DoS** 被采用，即攻击者控制多个源且让每个源向目标猛烈发送流量。分布式攻击往往利用僵尸网络。
	- 丙、对于无线传输设备，在其附近放置一被动接收机可接收到传输的每个分组的副本，这被称为**分组嗅探机**。对于广播分组的有线接入技术，如以太网、电缆接入技术，也易受到嗅探攻击。
	- 丁、攻击者将带有虚假（冒充的）源地址的报文注入互联网，进而执行某些嵌入在该分组中内容的命令，这被称为 **IP 哄骗**。端点鉴别可以解决这个问题。
- 以下是本章最后一节 1.7 节〈计算机网络和因特网的历史〉的内容。
	- <time>17:46</time> *白程旺，学完吃饭，祝你好运。*
- 二十世纪六十年代，因特网诞生之初，采用电路交换的电话网在通信领域占据统治地位。为了计算机之间的交流，由于用户产生流量具有突发性，即活动的间断性，表现为发送命令后静止等待应答或对接收到的响应进行思考，三个研究小组分别发明了分组交换。*看来，因特网的核心就在分组交换；确实，网络核心就在实现分组交换的链路层交换机和路由器组成的网络中。*
- 二十世纪七十年代，世界上产生了多种独立的、封闭的分组交换网络，其中作为它们的鼻祖的 ARPAnet 此后一直承担因特网主干流量。将这些网络互联的工作启动，这在本质上是创造网络的网络。创建的互联网的体系结构的原则体现在 TCP 协议中，出于不可靠的、非流控制的、端到端服务的重要性，IP 协议从 TCP 中分离出来，UDP 协议也被研发出来。*因特网的主要内容正在于它的协议中，而它的所有协议被统称为 TCP/IP 协议，这体现两者的重要性。*
- 二十世纪八十年代，联网主机激增，TCP/IP 协议被所有主机部署。NSFNET 成为连接区域网络的基本主干。TCP 协议扩展，以实现基于主机的拥塞机制。域名系统（DNS）诞生，用于将人类识别的因特网地址映射到 IP 地址上。
- 二十世纪九十年代，ARPAnet 与 NSFNET 退役，因特网主干流量由商业因特网服务提供商承载。因特网商业化。万维网应用程序出现，并进入千家万户。Web应用程序配置，众多互联网巨头诞生。HTML、HTTP、Web服务器和浏览器诞生。Detscape 公司研发具有 GUI 接口的浏览器，微软公司与之针锋相对，以微软获胜而告终。*这是著名的第一次浏览器大战。*
- 二十一世纪初，因特网已支持数百流行的应用程序，其中四者备受欢迎，分别为电子邮件（可浏览电子邮件及附件）、Web（包括 Web 浏览与电子商务）、即时通讯、MP3 对等文件共享。因特网金融市场繁荣。
- 至今，关于因特网的最新进展，作者提到，基础设施的部署建立高速因特网为媒体应用创造条件；高速公共 WiFi 网络与中速蜂窝电话网（4G）的发展推动手持设备的出现；在线社交网络成为用户「生活」的场所，为新的联网应用与分布式游戏创建了平台；在线服务商如谷歌和微软已广泛部署自己的专用网络，将它们与各自的数据中心连接，并且直接与较低层 ISP 连接，使得用户访问云端资源仿佛在自己的计算机中；云服务发展。
- *[[2022-09-20]]，下午，三个小时，至 55 页，第一章结束。*
---
#### 应用层
- 作者指出，网络应用是计算机网络存在的理由；如果不存在有用的应用，就没有必要设计支持它们的网络协议了。
- 因特网应用包括：基于文本的应用，电子邮件、文件传输和新闻组；万维网，搜索、冲浪和电子商务；即时通讯；对等（P2P）文件共享；IP 电话；视频会议；用户共享视频和点播电影；多人在线游戏；社交网络应用（*社交网络，将社会关系网络搭建在因特网的通信链路和路由器网络上*）；移动应用程序。
	- *万维网，又称为全球广域网，简称为 Web ，是由超文本网页组成的信息系统，它们通过超链接彼此导向。万维网只是因特网的应用之一。*
- 研发网络应用程序的核心是跨端系统而经由网络通信。因此，研发时须编写在多端系统上运行的应用程序，它们可能是相同的，也可能是不同的，*可以跨端通信即可*。
	- 编写应用程序不必考虑在网络核心设备如路由器和链路层交换机上运行的软件，因为它们并不在应用层起作用。这种设计，使应用程序被限制在端系统中。
- 网络体系结构对于应用程序开发者而言是固定的，为应用程序提供了特定的服务集成。**应用程序体系结构**则由应用程序开发者设计，它规定了如何在各种端系统上组织该应用程序。现代应用程序所使用的两种主流的体系结构是客户-服务器体系结构和对等（P2P）体系结构。
	- 在**客户-服务器体系结构**中，常开的服务器主机服务于来自客户的请求。客户之间不直接通信。服务器拥有确定的、周知的 IP 地址，客户向此地址发送分组、与之联系。这种体系的著名的应用程序有 Web 、FTP 、Telnet 和电子邮件。*Telnet 即虚拟终端，用户通过账户和密码验证身份后在本地主机输入命令，让已连接的远程主机执行。*
	- 在客户-服务器体系结构中，单台主机往往不堪重负，因此配备大量主机的**数据中心**被用于创建强大的虚拟服务器。
	- 在**对等体系结构**中，应用程序在间断连接的主机对之间直接通信，它们被称为对等方。对等方不被服务器提供商所有，它们的数据驻留在用户控制的主机中，因此目前流行的多数流量密集型应用都采用对等体系结构，包括文件共享（BitTorrent）、即时通讯（Telegram）、对等方协助下载加速器（迅雷）、视频会议（Skype）。其中的某些应用具有混合的体系结构，服务器用于追踪用户的 IP 地址，而用户之间的报文在用户主机之间直接发送。
	- 对等结构体系的应用具有**自扩展性**，即对等方通过向其他对等方分发文件增加系统的服务能力。这种结构体系具有成本效率，它无需规模巨大的数据中心。但是，它由于高度非集中式结构，面临安全性、性能和可靠性挑战。
- 运行的程序被称为**进程**。同一端系统上的多个进程间通过进程间通信机制相互通信，这由操作系统规定。不同端系统上的多个进程则通过跨越计算机网络交换**报文**而相互通信。
	- 网络应用程序由成对的进程组成，它们通过网络相互发送报文。对于通信会话场景中的一对进程，我们将发起通信（即会话开始时发起与其他进程的联系）者标识为**客户**，在等待通信（即会话开始时等待联系）者标识为**服务器**。或者说，客户进程与服务器进程；也称为，应用程序的客户端和服务端。即使在对等体系结构中也这样标识。
	- 进程通过**套接字**软件接口向网络发送和接收报文。*进程 => 套接字接口 => 由操作系统控制的运输层协议（TCP）=> 因特网核心*。可知，套接字接口是端系统内应用层与运输层之间的接口。由于该套接字是建立网络应用程序的可编程接口，它又被称为应用程序和网络之间的**应用程序编程接口**（**API**）。*套接字是谁起的名字，真抽象😒。*
	- 应用程序开发者可以控制套接字在应用层的一切，但对运输层几乎没有任何控制权。应用程序开发者对运输层的控制仅表现在：选择运输层协议；设定有限的运输层参数，诸如最大缓存和最大报文段长度。
	- 进程之间通信须寻址，这通过由 **IP 地址**标识的主机地址以及由**端口号**识别的接收主机上的接收进程（接收套接字）实现。
- 开发应用程序时可选择运输层协议，它有四方面的度量指标，分别是可靠数据传输、吞吐量、定时和安全性。
	- 由于队列缓存溢出导致丢包或分组中比特损坏被丢弃等情况的存在，**可靠数据传输**要求确保由应用程序的一端发送的数据正确、完全地被交付给该应用程序的另一端。如果运输层协议提供这种服务，那么只要将数据传入套接字便可相信该数据能无差错地到达接收进程。以多媒体应用为代表的**容忍丢失的应用**可能会接受不提供可靠数据传输的运输层协议，这样由发送进程发送的某些数据可能不会到达接收进程。
	- 在跨端进程通信会话的场景中，**可用吞吐量**指发送进程能向接收进程交付比特的速率。它受到同时占用网络路径带宽的会话的影响，随时间波动。某些运输层协议能够以某种确定的速率提供确保的可用吞吐量。具有吞吐量要求的应用程序被被称为**带宽敏感的应用**，以电话和多媒体应用程序为代表；**弹性应用**则能根据当前可用带宽利用可供使用的吞吐量。
	- 运输层协议也能提供**定时**保证，实时交互式应用程序对这种服务有需求，它们为了数据的有效性而对数据交付的时间有严格的限制。
	- 运输层协议能在发送主机中加密由发送进程传输的所有数据，在接收主机中将数据交付给接收进程前解密这些数据，提供**安全性**保证。
- 因特网为应用程序提供两种运输层协议，分别为 TCP 和 UDP 。应用程序开发者在这两者之间选择。每个协议为调用它们的应用程序提供了不同的服务集合。
	- **TCP 服务模型**提供面向连接的服务和可靠数据传输服务。**面向连接的服务**是指应用层数据报文开始流动前，TCP 让客户和服务器交换运输层控制信息（**握手**），在两个进程的套接字之间建立 **TCP 连接**。双方的进程都可以在此连接上同时进行报文首发。当应用程序结束报文发送时，拆除该连接。
	- TCP 协议还具有拥塞控制机制，当发送方与接收方之间的网络出现拥塞时，该机制会抑制发送进程。这为因特网整体带来好处。
	- 为了提供安全性保证，因特网界在应用层对 TCP 加强，称为**安全套接字层**（SSL）。它是建立在 TCP 协议基础上的应用，提供类似于 TCP 的套接字 API 。
	- 关于 UDP ，只能说，上述 TCP 提供的服务它都不提供，它仅提供最小服务。由于 UDP 没有拥塞控制机制，应用程序可以以它选定的任意速率向网络层注入数据；因此，能够容忍数据损失且要求达到传输的最小速率才能工作的电话应用倾向于采用 UDP 协议。
- **应用层协议**定义了运行在不同端系统上的应用程序进程如何相互传递报文。这些内容包括：报文类型，如请求报文和响应报文；各种报文类型的语法；字段的[[语义]]；某一进程何时以及如何发送报文、对报文进行响应的规则。
	- 有的应用层协议由请求评论规定，如 HTTP 协议，位于公共域中；有的应用层协议是专用的，它们有意地不为公共域使用。
	- 应用层协议是因特网应用程序的重要组成部分。
- *[[2022-09-20]]，晚上，两小时半，至 64 页，2.1 节完。*
---
- Web 的应用层协议是**超文本传输协议**（**HTTP**），它是 Web 的核心。HTTP 由客户程序与服务器程序实现（*即它采用客户-服务器体系结构*）。两者运行在不同的端系统中，通过交换 HTTP 报文会话，HTTP 协议规定了如何传递报文。
	- **Web 页面**（**网页文档**）由对象组成。对象是单独的文件，由 URL 寻址。多数网页文档由一个 **HTML 基本文件**以及几个引用对象组成。HTML 基本文件通过对象的 URL 地址引用页面中的其他对象。URL 地址由存放对象的主机名和对象的路径名组成。
	- **Web 浏览器**实现 HTTP 的客户端。**Web 服务器**实现 HTTP 的服务器端，存储 Web 对象。
	- HTTP 使用 TCP 作为它的支撑运输协议。HTTP 的客户与服务器在运输层建立连接后，浏览器和服务器便可以经由套接字接口访问 TCP ，由此传递报文。
	- HTTP 是**无状态协议**，HTTP 服务器并不会保存关于客户的任何信息。*请求历史记录等。*
- 应用程序中客户与服务器可能为持续通信（客户连续地发出一系列请求，服务器分别对它们回应）、可能为间断通信（客户将这一系列请求周期性或间断性地发送），因此，当采用 TCP 协议时，开发者应当决定：这些请求/响应对分别采用单独的 TCP 连接发送，还是共用同一 TCP 连接发送。前者被称为**非持续连接**，后者被称为**持续连接**。HTTP 协议默认采用持续连接，也可配置非持续连接。
	- 非持续连接必须为每个请求对象建立和维护一个新的连接，每次建立连接须经过「三次握手」，耗费两倍**往返时间**（**RTT**）（即建立连接需要往返时间，请求和响应对象需要往返时间），并且对于每个这样的连接，服务器和客户端都要分配　TCP　缓存区和保持 TCP 变量，这对 Web 服务器带来严重的负担。
	- 因此，HTTP 协议默认采用持续连接，客户与服务器建立连接后后续请求和响应都可以经由该连接传递。
- HTTP 报文分为请求报文与响应报文。
	- **HTTP 请求报文**由三部分组成，第一行是**请求行**，其后续行是**首部行**，经一空行（回车换行）后是**实体体**。请求行有三个字段：方法字段、URL 字段、HTTP 版本字段。GET 方法无实体体，其传输字段可扩展 URL 附加于首部行，POST 方法常用来提交表单数据。
	- **HTTP 响应报文**由三部分组成，第一行是**状态行**，其后续行是首部行，经一空行后是实体体。状态行有三个字段：协议版本字段、状态码和相应状态信息。
- 由于 HTTP 是无状态协议，服务器为跟踪用户使用 **cookie** 。cookie 技术有四个组件：响应报文中的 cookie 首部行（Set-cookie）；请求报文中的 cookie 首部行（cookie）；用户端系统中保存的由浏览器管理的 cookie 文件；Web 后端的数据库。
	- cookie 的工作流程为：当用户首次提出请求时，服务器为用户设置可标识其身份的身份码（cookie）、保存在数据库并在响应报文的首部行中返回（Set-cookie），这将在用户本地设置该识别码，此后当该用户发送请求时，请求报文首部行都会附加该身份码，服务器收到请求后将身份码在数据库内检索确认用户身份。由此，cookie 在无状态的 HTTP 上建立用户会话层。
- **Web 缓存器**也叫**代理服务器**，它是能代表初始服务器（*与代理服务器相对的概念*）满足 HTTP 请求的网络实体。通过配置浏览器，用户的请求将首先指向代理服务器。代理服务器会在其存储空间内存储最近请求过的对象，如果用户请求它存储的对象，它便直接响应给用户，如果用户请求它未存储的对象，它便向初始服务器请求该对象并响应与存储副本。*由于它被首先指向而被称为代理服务器，由于它存储对象而被称为 Web 缓存器。*
	- 缓存器可以减少客户请求的响应时间，尤其在客户到缓存器间的瓶颈带宽高于客户到服务器间的瓶颈带宽时。缓存器可以减少机构到因特网之间的通信量，使机构不必增加其接入链路的带宽。通过缓存器，机构可以低成本地（不必增加接入带宽）构建高速局域网。缓存器可以总体上减少因特网上的流量。
	- 通过**内容分发网络**（CDN），内容服务公司如谷歌和奈飞在各地创建缓存器使流量本地化，降低了服务成本。
	- 为了防止已缓存的副本陈旧，缓存器有**条件 GET 方法**，即采用 GET 方法与 if-modified-since 首部行向初始服务器发送请求，以此确认副本是否需更新。
- 电子邮件系统有三个主要组成部分：**用户代理**、**邮件服务器**、**简单邮件传输协议**（**SMTP**）。用户代理允许用户阅读、回复、转发、保存和撰写报文（*邮件是报文*）。邮件服务器为用户指定接受邮件的邮箱，发送邮件时有**报文队列**。由此，发送邮件的流程为：甲用户代理 => 甲邮件服务器（及报文队列）=> SMTP => 乙邮件服务器（及乙的邮箱）=> 乙用户代理。
- 在邮件服务器之间，SMTP 采用对等体系结构。当邮件服务器发送邮件时，它被认为是 SMTP 的客户，当接收邮件时，它被认为是 SMTP 的服务器。
	- SMTP 在运输层采用 TCP 协议。当 SMTP 客户端发现待传递的报文时，它建立与服务器的 TCP 连接，SMTP 客户端与服务器握手后，客户端将报文发送给服务器（具体过程是：客户端 => 套接字 => TCP => 套接字 => 服务端）。（*这里经过 TCP 握手与 SMTP 握手。*）SMTP 一般不采用中间邮件服务器发送邮件。
	- HTTP 被认为是**拉协议**，即 TCP 连接由想要接收文件的客户发起；SMTP 被认为是**推协议**，即 TCP 连接由想要发送文件的客户发起。另外，HTTP 将每个对象封装在各自的报文中，SMTP 则将所有对象封装在同一报文中。
	- 邮件报文格式由首部行和空行分隔的报文体组成。首部行必须包含 `From:` 和 `To:` 字段，可选地包含 `Subject:` 和其他字段。报文体必须采用七位 ASCII 编码。*似乎 SMTP 握手的命令对应 HTTP 报文的请求行和状态行。*
- 在用户代理与邮件服务器之间，采用客户-服务器体系结构。用户代理采用 SMTP 协议即可向邮件服务器发送邮件，这与邮件服务器之间发送邮件类似（*都是推操作*）。在此过程中，邮件服务器的作用是将用户代理发送的 SMTP 命令中继至目标用户代理的邮件服务器；SMTP 命令可经多个 SMTP 服务器进行报文中继。采用邮件服务器的好处是它总是保持运行。
	- 但是，由于 SMTP 是推协议，用户代理不能通过它访问邮件服务器接收的邮件，因此需要**邮件访问协议**，有**第三版的邮局协议**（**POP3**）、**因特网邮件访问协议**（**IMAP**）和 HTTP 。
	- 用户代理建立与邮件服务器端口 110 上的 TCP 连接后，POP3 进行三个阶段的工作：在特许阶段，用户（明文）发送用户名和口令以鉴别用户；在事务处理阶段，用户取回报文，此时用户代理可对报文进行删除标记或者统计信息（这些都通过命令进行）；在更新阶段，用户发出 `quit` 命令结束该会话后，服务器删除那些标记删除的报文。POP3 服务器不会在会话过程中携带状态信息，尽管会保存来自用户的状态信息（例如删除标记）。
	- POP3 只能执行简单的命令，用户访问邮件可以选择下载并删除或下载并保留，但用户只能在本地主机的文件夹中组织邮件。IMAP 服务器为用户创建远程文件夹，并提供命令供用户远程组织与检索邮件。IMAP 服务器将维护会话的用户状态信息。此外，IMAP 允许用户获取报文的某些部分（而非全部）。
	- 采用 HTTP 协议则使用浏览器即可向邮件服务器收发邮件。此时，用户代理向邮件服务器发送邮件也可采用 HTTP ，而非 SMTP 。
- *[[2022-09-21]]，上午，三小时，至 83 页，2.3 节完。*
---
- 在因特网中，主机通过**主机名**或 **IP 地址**标识。前者便于人类记忆，而后者由于数字化、结构化特征而易被路由器识别。**域名系统**（**DNS**）提供两者之间的转换。DNS 是①一个由分层的 **DNS 服务器**实现的分布式数据库；②一个使得主机能够查询分布式数据库的应用层协议。它运行在 UDP 协议上，使用 53 号端口。
	- DNS 运行的方式是：其他应用的客户端将主机名发送给 DNS 客户端；DNS 客户端将带有主机名的请求发送给 DNS 服务器；DNS 服务器响应该请求，将带有该主机名对应的 IP 地址的报文反馈给 DNS 客户端；其他应用的客户端使用该 IP 地址发送报文。为了减少 DNS 服务产生的时延，常用的 IP 地址通常被缓存在临近的 DNS 服务器中。
	- 除主机名与 IP 地址转换外，DNS 还提供：**主机别名**服务，相对应的主机名被称为主机规范名；**邮件服务器别名**服务，并且，MX 记录允许邮件服务器与 Web 服务器使用相同的别名；**负载分配**，同一站点可能分布在多台服务器（它们被称为冗余的服务器）上，它们拥有不同的 IP 地址并形成 IP 地址集合，DNS 将这一 IP 地址集合与唯一的主机规范名映射，当用户向 DNS 服务器请求该主机名时，DNS 服务器以整个 IP 地址集合回应，并且，由于用户默认向靠前的 IP 地址发送请求，DNS 服务器每次回应时将这些 IP 地址的次序进行循环变动，以此在所有冗余的 Web 服务器上循环分配负载。
	- 全球分布大量的 DNS 服务器，它们以分层次的方式组织，分布式地存储域名数据库。这些服务器被分为三个层次：**根 DNS 服务器**，全球共四百余根服务器，由十三个不同的组织管理，它们提供顶级域服务器的 IP 地址；**顶级域（DNS）服务器**（ TLD 服务器），每个顶级域（`.com` `.org` `.edu`）和所有国家的顶级域（`.cn` `.uk`）都有顶级域服务器或服务器集群，其中 `.com` `.edu` 等由特定的公司管理，顶级域服务器返回权威 DNS 服务器的 IP 地址；**权威 DNS 服务器**，任何具有公共可访问主机的组织机构都必须提供公共可访问的 DNS 记录并将它们映射为 IP 地址，这些组织机构必须使用（无论是租用还是自建）权威 DNS 服务器存储这些记录。
	- 在上述的层次结构之外，有**本地 DNS 服务器**，也叫默认名字服务器，它们由因特网服务提供商（ISP）提供，当本地的主机发出 DNS 请求时，该请求被发往本地 DNS 服务器，它起代理作用，并将该请求转发至 DNS 服务器层次结构中。由此，本地主机请求 IP 地址的具体流程可能是：本地主机将域名发送至本地 DNS 服务器，本地 DNS 服务器向根 DNS 服务器查询顶级域服务器地址（发送请求后，返回顶级域服务器的 IP 地址，下述查询皆如此，凡往返两次报文），本地服务器向顶级服务器查询权威服务器地址，本地服务器向权威服务器查询该域名对应的 IP 地址，本地服务器将该 IP 地址返回给本地主机。这一流程中共往返报文 8 次，由于权威服务器也是分层次的，因此请求查询权威服务器地址可能需要往返更多次。*例如 `wh.sdu.edu.cn` 与 `sdu.edu.cn` 可能是两层权威服务器。*
	- 上述这些查询可以是**递归查询**，也可以是**迭代查询**，前者是主机（服务器）向某一层次的 DNS 服务器查询某一域名后，该 DNS 服务器向其他 DNS 服务器查询后向该主机返回 IP 地址；后者是主机向某一层次的 DNS 服务器查询某一域名后，该 DNS 服务器将所需下一层的 DNS 服务器的 IP 地址直接返回给主机，然后由该主机再次进行查询以获得目标主机的 IP 地址。*代查与自助。*
	- 在上述情况下，往返报文多次产生时延，为解决这一问题，有 **DNS 缓存**机制。在这一机制中，当某一 DNS 服务器从报文中获得到域名与 IP 地址的映射时，在本地存储其副本，当收到关于已缓存映射的请求时，该 DNS 服务器便不必向层次体系请求而直接反馈 IP 地址。由于域名与 IP 地址的映射可能变动，因此这一缓存不是永久的，在一段时间后将被丢弃。由于顶级域名服务器总是被缓存，根服务器经常被绕过。
- 在实现 DNS 分布式存储数据库的所有 DNS 服务器中存储了**资源记录**（RR），其中提供主机名到 IP 地址的映射。每个 DNS 回答报文中包含一条到多条资源记录。资源记录包含四个字段：`Name` 、`Value` 、`Type` 、`TTL` 。其中，`TTL` 是该记录的生存时间，决定它何时从缓存中被删除。 
	- `Name` 和 `Value` 的值取决于 `Type` ，它们可能的情况有：如果 `Type = A` ，则 `Name` 是主机名，`Value` 是该主机名对应的 IP 地址；如果 `Type = NS` ，则 `Name` 是域名，`Value` 是该域名对应权威 DNS 服务器的 IP 地址；如果 `Type = CNAME` ，则 `Name` 是主机别名，`Value` 是其对应的主机规范名；如果 `Type = MX` ，则 `Name` 是邮件服务器别名，`Value` 是其对应的邮件服务器规范名。为了获得主机或邮件服务器的别名，主机向 DNS 服务器的请求报文中带有记录的类型，由此主机别名与邮件服务器别名可以相同。
- DNS 报文由首部区域与实体区域组成，首部区域有 12 比特，其中 1 比特标识其为查询报文或回答报文，1 比特用于标识该回答报文（如果是）是由请求的权威 DNS 服务器回答的，1 比特用于表示该请求报文「希望递归」，1 比特表示发出该回答报文的 DNS 服务器「允许递归」。剩余 8 比特分别表示问题数以及回答、权威、附加信息的资源记录数。
	- 实体区域由四部分组成：问题区域包含正在查询的问题，包括 `Name` 与 `Type` 两个字段；回答区域可能包含多条资源记录；权威区域包含其他权威服务器的记录；附加区域包含其他有帮助的信息，例如 `Type = MX` 的请求的回答报文中可能在此区域附加该邮件服务器的 IP 地址。
- 由商业运营的**注册机构**负责验证注册域名的唯一性并将新注册域名输入至 DNS 数据库中。
- 2.4 节〈 DNS 〉的内容至此，以下内容关于流媒体与内容分发。
- HTTP 流中，用户使用 `GET` 方法请求视频文件时，客户与服务器建立 TCP 连接以传输该视频，这些视频数据先被缓存，等缓存中的字节数量超过阈值时客户应用程序便可以播放该视频。对于流式视频应用，应用程序周期性地抓取缓存中的帧，将它们解压缩并在用户的频幕上展现。
	- 但传统的 HTTP 流不能根据用户的带宽而选择视频的比特率，它的改进被称为**经 HTTP 的动态适应性流**（DASH），视频被分割为较小的视频段（几秒），每个视频段被编码为不同比特率的版本，客户端动态地根据带宽选择不同版本的视频段，接收其数据块。每个视频版本被储存在服务器中有各自的 URL ，服务器提供**告示文件**说明 URL 及对应比特率，客户在请求报文中为每块指定 URL 和字节范围，一次选择一块。
- 为了向全球用户分发巨量的视频数据，几乎所有主要的视频流公司都使用**内容分发网**（CDN），即在全球各地部署数据中心（服务器集群），存储视频副本，并将用户请求定向到最佳体验的数据中心位置。为了获得最佳体验，内容分发网可能为用户选择最近的集群，也可能**实时测量**流量条件。
- 以下是 2.7 节〈套接字编程〉的内容。
	- *学完本章可以吃饭，快乐。*
- 网络应用程序有两类，一类是开放的，由协议标准所定义的操作实现，只要两个应用程序都遵守该标准，它们便可以相互通信；另一类是专用的网络应用程序，它的应用层协议没有公开发布。
- 当使用 UDP 时，应用程序经套接字接口向运输层发送的分组中附着目的地址，其包括目的主机的 IP 地址和目的应用程序的端口号。当一个套接字生成时，操作系统为它分配一个**端口号**作为标识符。*套接字对应端口。*
- 当使用 TCP 时，客户进程与服务器进程进行任何实际数据传输之前，先由特殊的套接字（被称为欢迎套接字）建立 TCP 连接，这被称为三次握手。连接后，对于连接生成新的套接字用于传输数据，它被称为连接套接字。应用程序经连接套接字发送的分组不必附加目的地址。
	- *Node.js 中似乎只提供了 HTTP 模块，而没有提供更基础的 socket 模块。今天晚上回到宿舍以后你可以试试套接字编程。*
- *[[2022-09-21]]，下午，三小时半，至 113(120) 页，第二章完。*
---
#### 运输层
- 运输层将网络层的在两个端系统之间的交付服务扩展到运行在两个不同端系统上的应用层进程之间的交付服务，这被称为**运输层的多路复用**和**多路分解**。
	- 网络层建立端系统之间的逻辑通信，运输层在此基础上建立不同端系统上应用进程的**逻辑通信**。主机（或应用进程）间经由逻辑通信发送报文而不必关注承裁这些报文的物理基础设施的细节。
	- 运输层协议只在端系统中工作，路由器只能作用于网络层数据报的首部，不能处理被其封装的运输层报文段。运输层提供的服务受制于网络层的服务，由于网络层提供的服务是不可靠的，能否提供可靠交付仅取决于运输层协议，它以自己的方式提供可靠的服务。
	- 网络层采用网际协议（IP），它的服务模型是**尽力而为交付服务**，也就是说它尽最大努力交付报文段但不做任何确保。因此，它被称为**不可靠服务**。
	- UDP 同样提供不可靠服务，而 TCP 提供可靠数据传输与拥塞控制机制。
- 实际上，运输层的报文段并非直接交付给应用进程，而是交付给套接字。为此，端系统的每个套接字需要唯一可识别的标识符。将运输层报文段中的数据交付到正确的套接字的工作被称为**多路分解**。
	- 从源主机的不同套接字处接收报文并将其封装上首部信息生成报文段，然后将这些报文段传递到网络层，这些工作被称为**多路复用**。
	- *所谓多路，是指网络层传输的数据是端系统上所有应用进程的数据的集合，因此运输层的工作便是将它们打包（多路复用）与分解（多路分解）。*
	- *一小时。上午 11:50 ，去吃饭。*
	- 在普遍意义上，多路复用与多路分解与在某层（运输层或其他层）的单一协议被较高层的多个协议使用有关。
- 网络层通过 IP 地址识别主机，运输层则通过端口号识别主机上的套接字。因此在运输层报文段的首部字段负载源端口号与目的端口号。**源端口号字段**和**目的端口号字段**。端口号是 16 比特的数，其大小在 0 到 65535 之间，其中 0 到 1023 的端口号被称为**周知端口号**，它们被周知应用协议使用。
	- UDP 套接字由包含目的 IP 地址和目的端口号的二元组标识。因此，源地址（ IP 地址与端口号）不同的两个 UDP 报文段如果目的地址相同，将被定位到同一套接字。但是，尽管不将其作为标识符，UDP 报文段的首部也包含源端口号，供服务器从中（结合数据报首部的 IP 地址）提取返回地址。
	- TCP 套接字由包含源 IP 地址、源端口号、目的 IP 地址和目的端口号的四元组标识。因此，源地址不同的两个 TCP 报文段如果目的地址相同，将被目的主机定位到不同套接字。特殊的是，建立 TCP 连接时，TCP 客户向服务器给定的套接字（采用欢迎端口号）发送连接建立请求报文段，收到报文段后，服务器定位在该端口的等待接受连接进程会为这次连接创建新的套接字，标识为**连接端口号**，此后客户与服务器通过连接端口号交流。*欢迎端口号与连接端口号可以是相同的，例如 Web 服务器使用 80 端口等待与建立连接。*
- 通过应用层协议的控制，采用 UDP 协议的应用程序也能实现可靠数据传输，例如 Chrome 浏览器采用的 QUIC 协议。但 UDP 协议本身的高丢包率无法解决，通过这种方法绕过 TCP 的拥塞控制机制而大量传输流媒体数据将导致采用 TCP 协议的应用程序（由于 UDP 造成的高丢包率与拥塞）大幅减小它们的速率（确保可靠传输），并且由于路由器的分组溢出（拥塞），只有极少的 UDP 分组能成功传输（毕竟 UDP 协议不提供可靠传输）。
- UDP 报文段的首部只有四个字段，占 32 比特（ 8 字节），分别是源端口号、目的端口号、长度和检验和。长度字段指示 UDP 报文段的字节数，包括首部加数据。接收方使用检验和检查在该报文段中是否出现差错。
- 可靠数据传输要求某一协议为上层实体提供服务[[抽象]]，使数据可以通过可靠信道进行传输，而不会损坏或丢失，并且保证数据以发送顺序交付。（*可靠数据传输的三个要求：数据不会损坏，数据不会丢失，按顺序交付。数据损坏是指数据中某一比特由 0 变为 1 或反之。*）这样的协议被称为**可靠数据传输协议**，它的下层协议未必是可靠的。
	- 如果经底层信道（由下层协议传输的信道）的分组中比特可能受损（称**比特差错信道**），可以采用**自动重传请求协议**（ARQ），使接收者对接收到的信息进行差错检测（例如 UDP 的检验和），并提供反馈报文，内容为**肯定确认**（ACK）或**否定确认**（NAK），当发送者收到来自接收者的否定确认时，发送方将重传该分组文。即，自动重传请求协议有三个功能：差错检验、反馈报文、重传。在此协议中，当发送方等待反馈确认时，它不能从上层中获得更多数据以发送，只有当获得肯定确认后，它才能获得数据并发送。这样的协议被称为**停等**协议。*也就是说，只有当前这个分组得到肯定确认后，发送方才能发送下个分组；如果得到否定确认，便重传，直到得到肯定确认。*
	- 此处，发送方存在两个状态，分别是等待来自上层的调用（发送新分组）和等待反馈报文（重发），这构成它的**有限状态机**（FSM），类似地，接收方也有有限状态机，其只有一个状态，即等待来自下层的调用，其对应的可执行操作为接收、检验并发送反馈报文。有限状态机由有限数量的状态（一个或多个）及对应的若干可执行的操作（如上括号内）组成，协议在这些状态间变迁。*事件与行为。*
	- 问题在于，反馈报文也可能出错！为了解决这个问题，如果再套用一层这样的协议，那么，反馈反馈报文的反馈报文也可能出错！（*因此不这么做。*）如果发送方一旦发现反馈报文可能出错便重传该分组，那么在该反馈报文的内容为肯定确认时将在接收方处引入**冗余分组**。为了排除冗余分组，在数据分组中添加**序号**字段，存放发送方对数据分组的编号，在停等协议的情况下，序号字段只需 1 比特（*那么，它只有 0 和 1 两个值*），用于表示当前分组是否被重传（*接收者可以根据之前对分组的检验结果决定是否保留这一重传的分组；每次发送新的分组，便变更序号，这样重传的分组序号不变，故可知*）。这样，也可以取消否定确认，当收到两次肯定确认（即**冗余 ACK** ）时便重传，此时反馈报文中也应当附着序号字段，由此发送方便可以从反馈报文中检查被确认的分组序号。
	- 如果该比特差错信道可能丢包（称**具有比特差错的丢包信道**），那么在重传协议的基础上应当具有检测丢包的机制。简单的做法是，如果发送方等待足够长的时间都接收不到来自接收方的回应，那么便重传该分组；所谓足够长的时间，至少是发送方与接收方之间的一个往返时延加上接收方处理一个分组所需的时间。此时，仍然可以使用上述序号字段排除冗余分组。为了实现基于时间的重传机制，需要设定**倒计数定时器**，每次发送（或重传）分组时，启动定时器，定时期间收到回应便采取适当的动作，定时器终止而未收到回应则重传该分组。
	- *由上，通过重传，差错检验与反馈报文解决数据损坏问题，定时器解决丢包问题，序号解决顺序交付问题，我们便得到了一个可靠数据传输协议。*
- 但是，上述协议作为停等协议，对信道的利用率极低。它的改进是**流水线**协议，即发送方不必等待肯定确认即可发送下一分组。为此，应当增加序号的范围，使其可以表示流水线上的多个分组；发送方应当缓存那些到达但没有确认的分组，接收方也应当缓存那些已正确的分组。（ TCP 协议使用 32 比特的传输数据流的字节数表示序号，而非使用分组顺序。）解决流水线的差错恢复的两种基本方法是：**回退 N 步**（GBN）和**选择重传**（SR）。
	- 在**回退 N 步协议**中，允许发送方发送多个分组而不必等待确认，但流水线中未被确认的分组不得超过规定的最大允许数 N 。可以将基序号（base）定义为最早未被确认分组的序号，将下一序号（nextseqnum）定义为下一个待发分组的序号。可处理的最大允许数 N 又被称为**窗口长度**，这一协议也被称为**滑动窗口协议**。
	- 由此，发送方必须响应三个类型的事件，分别是：上层的调用，被上层调用时，发送方检查窗口是否已满，即是否存在 N 个未被确认的分组，如果窗口未满，则发送该数据，如果窗口已满，则将该数据返回给上层；收到肯定确认，在回退 N 步协议中，确认反馈表示反馈报文中序号字段以前的所有分组均已正确接收，这被称为**累积确认**；超时事件，协议使用对基序号分组使用定时器，收到肯定确认时，重新定向基序号（移动窗口），定时器重新启动，超时时，重发所有已被发送但未被确认的分组，这便是回退 N 步的含义。*基于事件的编程。*
	- *下午四点半，今日已学习五小时。学至六点半。*
	- 接收方的动作是：每正确且按序接收到一个分组，则发送带有其序号的肯定确认，并将其交付给上层，否则（数据损失或失序）丢弃该分组并发送否定确认。为了检验分组顺序，接收方应当维护下一个按序接收的分组的序号信息。
	- 回退 N 步协议由于重传大量的分组而影响性能，**选择重传协议**允许发送方仅重传它怀疑在接收方出错（丢失或受损）的分组。为此接收方接收正确的分组，并为其返回肯定确认，缓存失序的分组，直到所有丢失的分组都被接收，这才把它们一并交付上层。发送方为每个分组定时，超时未收到肯定确认则重传之。只有当自基序号开始的某一分组区间内的所有分组都得到确认，发送方才移动窗口。*选择重传协议在回退 N 步协议基础上做选择，它也是基于窗口的。*
	- 对于选择重传协议而言，窗口长度必须小于或等于序号空间大小的一半。这是由于发送方窗口与接收方窗口并不总是一致，当某一序号重复出现（序号可以被重复使用）时，接收方难以确认这是重传，还是携带新数据的分组。*发送方的窗口的分组区间是 `[base, base + N - 1]` ，接收方的窗口的分组区间是 `[n, n + N - 1]` ，n 表示上一个确认的有序分组。那么这里讨论的 n 与 N 之间的关系就是：`n ≤ N/2` 。*
- *好神奇呀，当你输入某个网址或提交某个表单时，有些比特潜在交叉盘桓的网络里为你万里奔波，它们真是一群精灵。*
- 底层信道模型中，分组可能重新排序，这表现为：某一序号或确认号为 x 的旧分组的副本重复出现，即使发送方和接收方的窗口中都不包含 x 。一般而言，它们会被缓存，然后在某一时刻释放。但是，由于序号可以被重复使用，这可能造成冗余分组（*占用新数据的位置*），干扰数据传输。为此，应确保某一序号不被重新使用，直到发送方确信网络中不存在该序号分组的副本，可以假定分组在网络中存活的时间为某一固定最大时间量。TCP 协议将分组寿命假定为 3 分钟。
- *[[2022-09-22]]，下午，六个小时，至 152 页，3.4 节完。*
---
- TCP 协议是面向连接的，当两个应用进程之间传递报文时，两者必须首先相互发送些报文段，建立确保数据传输的参数，连接双方初始化 TCP 连接的状态变量。TCP 连接是逻辑连接，它是由连接双方的共同状态规定的。TCP 连接提供**全双工服务**，参与连接的必须是一对主机，且连接双方之间可以相互传输数据。
	- 建立 TCP 连接的过程是：客户发送请求建立连接的 TCP 报文段；服务器发送回应请求的 TCP 报文段；客户发送可携带有效载荷（应用层数据）的 TCP 报文段。由于两台主机间往返三个报文段，因此被称为**三次握手**。
	- 建立连接后，客户进程经由套接字传递数据，数据一旦通过套接字，它便由 TCP 控制。TCP 将这些数据引导至**发送缓存**中，在它方便时（起码在建立连接后）以报文段的形式向网络层发送数据；服务器端对应有接收缓存。TCP 每次传输的数据数量受限于**最大报文段长度**（MSS），它通常根据由本地发送主机发送的最大链路帧长度（即**最大传输单元**，MTU）设置，使得报文段被封装在数据报后，数据数量加上 TCP/IP 首部长度适合单个链路层帧。最大报文段长度通常设置为 1460 ，这是由于以太网和 PPP 链路层协议都具有 1500 字节的最大传输单元，而 TCP/IP 首部通常占 40 字节。注意数据数量不包括报文段首部，也就是最大报文段长度不包括报文段首部。
- TCP 首部包括：源端口号和目的端口号；检验和字段；32 比特的序号字段和 32 比特的确认号字段；16 比特的接收窗口字段，用于流量控制；4 比特的首部长度字段；选项字段，用于发送方与接收方协调最大报文段长度，或在高速网络环境下用作窗口调节因子；6 比特的标志字段。选项字段是可选的与可调节长度的，如果不考虑它，TCP 首部一般是 20 字节。
	- 标志字段可能的内容是：**ACK** ，表示对已被成功接收报文段的确认；**RST** 、**SYN** 和 **FIN** 用于连接的建立和拆除；CWR 和 ECE 通告拥塞；PSH 表示接收方应立即将该报文段传输给上层；URG 表示该报文段中包含被上层实体置为紧急的数据。紧急数据的最后一个字节由 16 比特的紧急数据指针字段指出。
	- TCP 将数据视为无结构的、有序的字节流，它将序号建立在字节流上，而非报文段的序列上。某报文段的**序号**因此是该报文段首字节的字节流编号。某报文段的**确认号**是该报文段的发送方期望接收的下一字节的序号（下一报文段首字节的字节流编号；下一报文段的序号）。当一方主机接收到的报文段失序时，它将在反馈报文段中确认第一个丢失的字节为止的字节，这被称为**累计确认**。*也就是说，它只确认丢失的第一个字节的序号，而不是提供丢失的字节序号的范围。*
	- 由于 TCP 连接提供全双工服务，因此一方对另一方的确认反馈可以被**捎带**在它发送给另一方的数据报文段中，而不必单独发送反馈报文。
	- *上午十二点，已学习一小时，去吃饭。*
- TCP 通过超时重传解决报文段的丢失问题。为了确定超时间隔，TCP 在某一时刻测量报文段的**样本往返时间**（SampleRTT），并对以往的估计往返时间与这次测量的样本往返时间加权平均得当前的**估计往返时间**（EstimatedRTT）。样本往返时间权重更高，这是由于它更能反映当前网络的拥塞程度，这种加权平均方式在统计学中称为**指数加权移动平均**。TCP 也会测量往返时间的波动程度，称作**往返时间波动值**（DevRTT）。
	- TCP 由往返时间的估计值与波动值设置**超时间隔**（TimeoutInterval），它等于估计值加四倍的波动值。每次出现超时后，超时间隔将被加倍，避免由于超时间隔过短导致的超时。这也是为了避免由于拥塞造成不断重传而加剧拥塞。每次接收到报文段并更新估计往返时间后，超时间隔将被重新计算。
	- TCP 为所有已发送但未被确认的报文段设置单一的重传定时器，它们共用这一个定时器。（*这意味着实际上只为已发送但未被确认的第一个报文段设置定时器，即基序号报文段。*）当定时器超时时，重发该报文段，并重启定时器。由于 TCP 采用累积确认，当确认号大于基序号时，发送方将更新其基序号，并重启定时器；如果确认号等于基序号，发送方将重发该报文段，并重启定时器。
	- 上述情况下，发送方通过超时确认是否丢包从而决定是否重传，但现实中，当接收方接收到大于确定号的报文段时便可确定发生丢包，此时，由于 TCP 不存在否定确认，因此接收方再次发送带有当前确认号的报文段，由于发送方已接收到带有该确认号的报文段，因此这被称为**冗余 ACK** 。也就是说，当发送方接收到两次带有相同确认号的报文段时，它便可以确定序号为该确认号的报文段已丢包，从而重传，这减少了长超时周期导致的时延，因而被称为**快速重传**。实际中，当发送方接收到三个冗余 ACK 时才执行快速重传，这是由于一旦发生丢包，大于确定号的报文段接连到达，接收方势必发送大量冗余 ACK 。*之所以要求三个，可能是由于报文段可能乱序到达，也就是说存在序号在后的报文段先到达的情况，此时接收方发送冗余 ACK ，但接着序号在前的报文段也到达了，此时不必重传。*
	- 上述两段表明，TCP 的流水线不同于回退 N 步协议，后者的接收方将丢弃所有失序的报文段、发送方将重传所有已发送但未被确认的报文段；也不同于选择重传协议，后者的接收方将有选择地确认失序报文段，而不是累积确认最后一个正确接收的有序报文段。TCP 可以视作两者的混合。
- 为了避免应用程序读取数据较发送方发送数据缓慢导致的接收缓存溢出，TCP 提供**流量控制**服务。为此，TCP 须确认应用程序从缓存读取的数据流的最后一个字节的编号（已读字节号）与从网络中到达并置于接收缓存的数据流的最后一个字节的编号（已接受字节号），确保它们的差值应小于接收缓存中可容纳的字节数（缓存总量）。由三者可得缓存可用空间量（**接收窗口**，rwnd）为缓存总量减去已读字节号与已接收字节号的差值。当 `rwnd = 0` 时，接收方将向发送方发送该信息，要求停止发送数据，直到缓存被清理。实际上，为了避免发送方被阻塞，发送方将继续发送只有 1 字节数据的报文段，接收方将对它们进行确认，直到 `rwnd != 0` 时，在确认报文中提供非零的 rwnd 值。*rwnd 似乎在选项字段。*
- TCP 连接建立的过程为：第一步，客户发起请求建立连接的报文段，该报文段不包含应用层数据，其 SYN 位（位于标志字段）的值为 1 ，因此被称为 **SYN 报文段**，它的序号是用户随机选择的初始序号。第二步，携带 SYN 报文段的 IP 数据包到达服务器后，服务器从中提取 SYN 报文段，为该 TCP 连接分配 TCP 缓存和变量，并向客户发送允许建立连接的报文段。该报文段也不包含应用层数据，它的 SYN 位被设置为 1 ，它的确认号是上述用户的初始序号 + 1 ，它的序号是服务器随机选择的初始序号，它被称为 **SYNACK 报文段**。第三步，收到 SYNACK 报文段后，用户也为该连接分配缓存和变量，并发送报文段对 SYNACK 报文段确认，该报文段的确认号为上述服务器的初始序号 + 1 ，它可以携带应用层数据，此时连接已经建立，该报文段的 SYN 比特为 0 。这被称为**三次握手**。*三次握手中，双方分别为连接分配了缓存和变量，各自通报了其使用的初始编号。注意，为 TCP 连接分配缓存和变量，需要对方的初始编号。*
	- TCP 连接关闭的过程为：客户（也可以是主机，双方都可以提出关闭连接）向主机发送 FIN 位为 1 的终止报文段，并释放缓存与变量（关闭连接）；服务器接收 FIN 报文段后，返回确认报文段，并向客户发送它自己的终止报文段，同时释放缓存与变量（关闭连接）；客户最后确认服务器的终止报文段。
- *学完以后，你可能需要将这篇笔记分解为概念，作为复习与整理。*
- 在探究 TCP 协议的拥塞控制机制前，先讨论拥塞控制的一般原理。
	- 假设有两台源主机以相同的速率发送数据，它们与目的地间的连接共享一台无限缓存的单挑路由（*大概是说该链路仅存在唯一一台路由*）。设该共享链路的容量为 R ，那么，当这两台源主机发送速率超过 R/2 时，它们的吞吐量只能达到 R/2 ，也就是说，在共享链路的情况下，它们的吞吐量上限是 R/2 。并且，当发送速率接近 R/2 时，由于[[#^traffic-intensity|流量强度]]接近 1 ，路由器输出队列趋于无限增加，源与目的地间的排队时延趋于无限，尽管在无限缓存的假设下不会丢包。
	- 假设上述两台源主机与目的地间共享的路由器的缓存是有限的，这意味着排队溢出时将发生丢包。假设上述两个连接都是可靠的，即只有在丢包的情况下源主机才会重发数据包。此时，运输层向网络层发送报文段的速率（单位为字节每秒）是发送速率与重传速率的和，它被称为网络的**供给载荷**。如果主机只在路由器缓存有空闲时才发送数据，那么不会丢包与重发，发送速率仍等于供给载荷，此时平均主机发送速率不能超过 R/2 。如果主机确定一分组已丢失时将重传该分组（假设它判断无误），若它将供给载荷设置为 R/2 ，则有 R/3 的分组成功交付，也就是说供给载荷中将有 1/3 用于重传。 #？ 但主机并不能保证只有在确定某一分组已丢失时才重传该分组，假设每个分组被路由器转发两次，那么当供给载荷为 R/2 时，吞吐量接近 R/4 。
	- 假设有多台源主机发送数据，且它们与目的地间的连接共享有限缓存的多跳路由，那么这些连接在某一台路由器上处于竞争关系，当某一连接的流量占满该路由器的缓存时，其他连接的吞吐量几乎为 0 。此外，当上游路由器转发的分组由于下游路由器的拥塞而被丢弃时，该上游路由器为了传输该分组而占用的传输容量被浪费了。
- 在实践中，有两种主要的拥塞控制方法，分别是：端到端拥塞控制，网络层并不为运输层拥塞控制提供显式支持，端系统必须通过对网络行为的观察推测是否发生拥塞；网络辅助的拥塞控制，路由器向发送方提供关于网络中拥塞状态的显示反馈信息，这种反馈可以简单地用一比特指示链路中的拥塞情况。路由器可能向发送方发送直接反馈信息，也可能标记报文段令接收方向发送方通知该网络拥塞指示。
- 由于 IP 层不向端系统提供显式的网络拥塞反馈，TCP 协议使用端到端的拥塞控制，为此，它必须感知使发送方根据感知到的网络拥塞程度来限制其能向连接发送流量的速率。
	- 为了控制发送速率，TCP 连接在发送方创建名为**拥塞窗口**（cwnd）的变量，由此，发送方未被确认的数据量不得超过拥塞窗口与接收方的接收窗口的较小值。TCP 通过确认报文的时间来调节拥塞窗口长度，因此它被认为是**自计时**的。
	- 为了选择合适的发送速率，TCP 协议采取以下原则：报文段丢失表明拥塞，TCP 为此将降低发送速率，即减小拥塞窗口长度；确认报文段表明传输顺利，TCP 为此提高发送速率；综上，TCP 通过丢包事件与确认报文进行带宽探测，选择合适的发送速率。在此原则指导下，有 **TCP 拥塞控制算法**（AIMD），它包括三个主要的组成部分：慢启动、拥塞避免与快速恢复。
	- 在**慢启动**状态中，如 TCP 连接建立时，拥塞窗口被设置为 MSS/RTT ，这是很小的值，每次确认报文到达（经历一个 RTT），拥塞窗口便翻番，呈指数增长（*因此，慢启动并不慢*）。当经历由超时指示的丢包事件时，将此时的拥塞窗口减半设置为阈值，重置拥塞窗口，重启慢启动；当拥塞窗口达到阈值时，进入拥塞避免状态；当接收到三个冗余 ACK 时，将拥塞窗口减半，快速重传，并进入快速恢复状态。
	- 在**拥塞避免**状态中，拥塞窗口处于阈值，将其翻番则有拥塞的风险，因此每次接收到确认报文，只将拥塞窗口增加一个 MSS ，呈线性增长。当发生由超时指示的丢包事件时，将阈值更新为当前拥塞窗口减半，重置拥塞窗口，进入慢启动状态；当接收到三个冗余 ACK 时，将拥塞窗口减半，快速重传，并进入快速恢复状态。
	- 在**快速恢复**状态中，每收到一个冗余 ACK ，拥塞窗口增加一个 MSS ，当重传报文段的 ACK 到达时，TCP 降低拥塞窗口后进入拥塞避免状态。如果在此状态下发生超时事件，那么重置拥塞窗口，进入慢启动状态。
	- 上述 TCP 的拥塞控制被称为**加性增、乘性减**的拥塞控制方式，它的拥塞窗口随时间呈锯齿状。忽视时间很短暂的慢启动阶段，以及快速回复状态结束时减去有限几个 MSS ，总体上，TCP 的拥塞控制窗口锯齿的顶点设为 W ，那么最低点就是 W/2 ，则一条连接的平均吞吐量为 0.75W/RTT 。
	- 根据吞吐量公式，当 RTT 相同且不存在 UDP 应用时，同一瓶颈链路上的多个 TCP 连接将平等地分享该链路的带宽（W 相同）。RTT 不同时，RTT 较小的连接能获得更多带宽。当应用使用多个并行 TCP 连接传输数据时，它将获得更多带宽。运行在 UDP 协议上的多媒体应用将压制 TCP 的流量。
- *[[2022-09-23]]，五小时半，至 187(197) 页，第三章完。*
---
#### 网络层：数据平面
- 网络层连接任何一台主机与路由器。网络层的数据平面即网络层中路由器的功能，决定从输入链路到达路由器的数据包如何被转发到该路由器的输出链路之一。网络层的控制层面即网络范围的逻辑，它决定源端系统到目的端系统的端到端路径中路由器之间的路由方式，它通常由单独的一台远程控制机实现。*也就是说，协调路径上所有的路由器。*
	- 数据平面实现转发功能，控制平面实现路由选择功能。有路由选择算法。**转发**是指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作。**路由选择**是指确定分组从源目的地所采取的端到端路径的网络范围处理过程。*转发又称为交换。*
	- 路由器中有**转发表**，路由器检查到达分组首部的一个或多个字段值，用它们在转发表中索引，以决定转发分组。在传统的方法中，转发表由路由器中运行的路由选择算法控制，路由器间进行通信以计算转发表的值。在**软件定义网络**（SDN）中，转发表由远程控制软件计算并配置给路由器。
- *[[2022-09-24]]，至此，共学习 32 小时，本书搁置。*